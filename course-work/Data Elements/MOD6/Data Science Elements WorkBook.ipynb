{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "heading_collapsed": true,
    "hide_input": true
   },
   "source": [
    "# Python MySQL Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import MySQl Libaries\n",
    "import mysql.connector\n",
    "\n",
    "# Import Data Libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#Magic Function\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Add more imports above depending on the nature of analyzing that need to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "source": [
    "### Connecting Datset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV - only use if you have a CSV file to import into a dataframe\n",
    "df=pd.read_csv(r'...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use the method above to handle raw csv files with data only!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "### Connecting to MySQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "*Connect to ether MySQL Workbench or Azure MSSM platform to work with data sets direclty on the cloud*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import MySQL into a dataframe\n",
    "import mysql.connector as sql\n",
    "import pandas as pd\n",
    "\n",
    "db_connection = sql.connect(host='localhost', database='data_elements_class', user='root', password='Sp111579')\n",
    "\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "db_cursor.execute('SELECT * FROM mod3')\n",
    "\n",
    "table_rows = db_cursor.fetchall()\n",
    "\n",
    "df = pd.DataFrame(table_rows)\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM mod3', con=db_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Imports - import libaries needed to for data processing\n",
    "- Connection - connect to local or hosted server\n",
    "- Cursor - The MySQLCursor class instantiates objects that can execute operations such as SQL statements. \n",
    "- Exicute Cursor - execute SQL code to access db scehms/tables\n",
    "- FetchAll() - gett all Rows for current data set\n",
    "- DataFrame - add MySQL tables to Python dataframe\n",
    "- Read_sql select database table for inferences' \n",
    "\n",
    "-- https://dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlconnection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print head of MySQL database or csv file (5) only first 5 rows.\n",
    "\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preproccess Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use this to get quick stats on all columns of data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#describes the DBA column as you can see dunkin donuts is the most frequent\n",
    "print(df.YOUR_COLUMN.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Find NULL and Missing values in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#counts all null values in data frame (both column and rows)\n",
    "print(df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#counts all null values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#show null values\n",
    "print(df.isnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Chaeck Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preproccessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pandas** _ **dtype** _ **mapping:**\n",
    "\n",
    "| Pandas dtype | Python type | NumPy type | Usage |\n",
    "| --- | --- | --- | --- |\n",
    "| object | str or mixed | string\\_, unicode\\_, mixed types | Text or mixed numeric and non-numeric values |\n",
    "| int64 | int | int\\_, int8, int16, int32, int64, uint8, uint16, uint32, uint64 | Integer numbers |\n",
    "| float64 | float | float\\_, float16, float32, float64 | Floating point numbers |\n",
    "| bool | bool | bool\\_ | True/False values |\n",
    "| datetime64 | NA | datetime64[ns] | Date and time values |\n",
    "| timedelta[ns] | NA | NA | Differences between two datetimes |\n",
    "| category | NA | NA | Finite list of text values |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Resources to convert and work with datatypes\n",
    "\n",
    "> **Overview of Pandas Data Types:**  https://pbpython.com/pandas_dtypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get info back on core dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Use this section to work with only categorical data types for pre-proccessing and inferencing data into a new data frame to work with. \n",
    "\n",
    "*** Pandas object is a reference to string types.***\n",
    "\n",
    "| Pandas dtype | Code varible | Dataframe Varible|\n",
    "| --- | --- | --- | \n",
    " string  |    = 'object'   |   = obj_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add Categorical Data  Into a Seperate Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ADD CATEGORICAL DATA TO A NEW DATAFRAME\n",
    "# Selct all categorical data objects - obj_dfs = string\n",
    "obj_dfs = df.select_dtypes(include=['object']).copy()\n",
    "obj_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Do more work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Encoding Categorical Data\n",
    "\n",
    "This section incudes: \n",
    "- Encoding catergrical data varibles with bianry numbers with cat.codes\n",
    "- Dummy Varibles\n",
    "- One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Count colum valuesmake sure they are evenly processed \n",
    "obj_df[\"YOUR_COLUMN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Double Check DataTypes\n",
    "obj_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use cat.codes accessor labeling for colums in dataFrame - YOUR_COLUMN \n",
    "# YOUR_DISC = CREATE A NEW COLUM GHEAD DESCRIBTION FOR YOUR ENCODED DATA\n",
    "# (COPY THIS CODE BLOCK AND ADD COLUMN DATA FOR EACH COLUMN)\n",
    "obj_df[\"YOUR_DISC\"] = obj_df[\"YOUR_COLUMN\"].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cHECK NEW COLUMN WAS CREATED AT END OF TABLE WITH ENCODED VARIBLE FOR ENTIRE COLUMN\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Described Encoded data\n",
    "obj_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# obj_df CAN NOW BE USED WITH NUMARICAL DATA STATISITICS AND INFERENCES BELOW\n",
    "# Sperate values into X and Y values for stats\n",
    "# Use advanced grouping technuiqes below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Add Numarical Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">  Use this section to proccess numerical data by adding it to a new dataframe.\n",
    "\n",
    " \n",
    " <hr>\n",
    " **Working With Numarical Data:**\n",
    " \n",
    "| Pandas dtype | Code varible | Dataframe Varible|\n",
    "| --- | --- | --- | \n",
    "- int64  |    = 'int'   |   = num_df\n",
    "- float64   | = 'float'  |  = flt_df\n",
    "- datetime64 | = 'datetime'| = dat_df\n",
    "- bool      |  = 'bool'   |  = bol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*** Only Use the type you need and copy as many times to fit your data ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Selct all numarical  data objects - num_df = numbers\n",
    "num_df = df.select_dtypes(include=['int']).copy()\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selct all numarical  data objects - num_df = numbers\n",
    "flt_df = df.select_dtypes(include=['float']).copy()\n",
    "flt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selct all numarical  data objects - num_df = numbers\n",
    "dat_df = df.select_dtypes(include=['datetime']).copy()\n",
    "dat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selct all numarical  data objects - num_df = numbers\n",
    "bol_df = df.select_dtypes(include=['bool']).copy()\n",
    "bol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Do more work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Imputation\n",
    "\n",
    "> In this section use the code below pertianing to the data frame of interest to replace missing values, delete rows, impute data, and encode.\n",
    "\n",
    "* In statistics, imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as \"unit imputation\"; when substituting for a component of a data point, it is known as \"feature  imputation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Replace NULL and Missing Values\n",
    "\n",
    " - Best used on categorical data\n",
    " - Replace numarical data with MEAN vlaues\n",
    " \n",
    " <hr>\n",
    " \n",
    " CHANGE DATAFRAME TO FIT YOUR NEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Clean up REPLACE any missing values MAKE SURE TO CHANGE YOUR DATAFRAME\n",
    "#obj_dfS - OR -  obj_dfN\n",
    "obj_df[obj_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preproccess Data - YOUR COLUMN\n",
    "obj_df[\"YOUR_COLUMN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill in NULL values for column - Your_Column : Your_Value_to_be_Changed\n",
    "\n",
    "obj_df = obj_df.fillna({\"YOUR_COLUMN\": \"REPLACE_VALUE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#....copy code above for each column you need to even out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Replace NULL & Missing Fetures W/ MEAN Values - Numarical Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> axis=0 argument calculates the column wise mean of the dataframe so the result will be axis=1 is row wise mean so you are getting multiple values.\n",
    "\n",
    "- Specify index vlaue which = colum of data you want to work with.\n",
    "- Even if we do not specify axis = 0, \n",
    "- The method will return the mean over the index axis by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CALULATE full Dataframe MEAN  values for each column\n",
    "\n",
    "num_df.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# skip the NULL values while finding the mean \n",
    "num_df.mean(axis = 1, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Claulating Individual row of data MEAN/Average\n",
    "num_df[\"YOUR_COLUMN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_df['YOUR_COLUMN'].max(): For maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " num_df['YOUR_COLUMN'].min(): For minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sumerizes colum and dataframe data with stats\n",
    "print (num_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get both sets of stats back\n",
    "num_df['YOUR_COLUMN'].mean()\n",
    "num_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ploting Data Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Univariate Plotting With Pandas\n",
    "<hr>\n",
    "\n",
    "_Plot has methods to alter size and visualization styles such as **figplot(6,6)**\n",
    "to give the size of the plot an x vlaue of 6 inches and y vlaue of 6 inches. these can be changed_\n",
    " \n",
    "See dtrials of how to manipulate data with panads methods here:\n",
    "\n",
    "- Series data = https://pandas.pydata.org/pandas-docs/stable/reference/series.html\n",
    "- Datframes = https://pandas.pydata.org/pandas-docs/stable/reference/frame.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bar charts and categorical data\n",
    "\n",
    "> Bar charts are arguably the simplest data visualization. They map categories to numbers: \n",
    "\n",
    "- Replace df with your data fram unless you are still using orignail dataframe\n",
    "- Use with both categorical and numarical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ADD CATEGORICAL DATA COLUM TO GET STATS\n",
    "df['YOUR_CLOUMN'].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CONVERT Y AXIS TO PERCENTAGE VALUES\n",
    "(df['YOUR_CLOUMN'].value_counts().head(10) / len(df)).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Bar charts are very flexible: The height can represent anything, as long as it is a number. And each bar can represent anything, as long as it is a category.**\n",
    "\n",
    "- Nominal categorical variables include things like countries, ZIP codes, types of cheese, and lunar landers. The other kind are ordinal categories:\n",
    "- ordinal categories: things that do make sense to compare, like earthquake magnitudes, housing complexes with certain numbers of apartments, and the sizes of bags of chips at your local deli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# USING NOMINLA OR ORDINAL NUMARICAL DATA (CAN USE ENCODED, DUMMY DATA HERE)\n",
    "df['YOUR_CLOUMN'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Line charts\n",
    "\n",
    "** What would we do if the magazine rated things 0-100? We'd have 100 different categories; simply too many to fit a bar in for each one! In that case, instead of bar chart, we could use a line chart: **\n",
    "\n",
    "- Use Line chart to measureuniuqe values\n",
    "- Use line chart to visualize exccess amounts of data categories\n",
    "\n",
    "> Unlike bar charts, they're not appropriate for nominal categorical data. While bar charts distinguish between every \"type\" of point line charts mushes them together. So a line chart asserts an order to the values on the horizontal axis, and the order won’t make sense with some data. \n",
    "\n",
    "<hr>\n",
    "\n",
    "** Suppose that we're interested in counting the following variables: **\n",
    "\n",
    "- The number of tubs of ice cream purchased by flavor, given that there are 5 different flavors. (NOMINAL) = BAR CHART\n",
    "- The average number of cars purchased from American car manufacturers in Michigan.              (NOMINAL) = BAR CHART   \n",
    "- Test scores given to students by teachers at a college, on a 0-100 scale.                      (ORDINAL) = LINE CHART\n",
    "- The number of restaurants located on the street by the name of the street in Lower Manhattan.  (ORDINAL) = LINE CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['YOUR_CLOUMN'].value_counts().sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Area charts\n",
    "\n",
    "> Area charts are just line charts, but with the bottom shaded in. That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use numarical ordinal data\n",
    "df['YOUR_CLOUMN'].value_counts().sort_index().plot.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Interval data\n",
    "\n",
    "Interval variables are the wind speed in a hurricane, shear strength in concrete, and the temperature of the sun. An interval variable goes beyond an ordinal categorical variable: it has a meaningful order, in the sense that we can quantify what the difference between two entries is itself an interval variable.\n",
    "\n",
    "For example, if I say that this sample of water is -20 degrees Celcius, and this other sample is 120 degrees Celcius, then I can quantify the difference between them: 140 degrees \"worth\" of heat, or such-and-such many joules of energy.\n",
    "\n",
    "- Line charts work well for interval data. Bar charts don't—unless your ability to measure it is very limited, interval data will naturally vary by quite a lot.\n",
    "\n",
    "- Use  histogram for interval variable in our dataset, price (we'll cut price off at 200$ a bottle; more on why shortly).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Histograms\n",
    "\n",
    "> Histogram is special kind of bar plot that splits your data into even intervals and displays how many rows are in each interval with bars. The only analytical difference is that instead of each bar representing a single value, it represents a range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calulates average data frame row values with selcted colum data \n",
    "# based on specific column data specified by the conditions (< 100 +-)\n",
    "df[df['YOUR_CLOUMN'] < 100]['YOUR_CLOUMN'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Use code below to test Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Not good for skewed data (Will only show one column)\n",
    "# Only use if data is numarical and not skewed!!!\n",
    "df['YOUR_CLOUMN'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check dataframe column (adjust (> 2000 to any number that fits your set)\n",
    "df[df['YOUR_CLOUMN'] > 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Frequency Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df['YOUR_CLOUMN'].value_counts().plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pie chart of entire dataframe\n",
    "df.plot.pie(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['YOUR_CLOUMN'].plot.pie(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bivariate Plotting With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Scatter plot\n",
    ">  Bivariate plot is essntially a scatter plot. A simple scatter plot simply maps each variable X, Y of interest to a point in two-dimensional space. \n",
    "\n",
    "- Plot shows and should be used to show correlations\n",
    "- Must use numarical data\n",
    "- Category data must be encoded to numarical data and seperated to X Y varibles\n",
    "- Best results data needs to be clean and even\n",
    "- Best used with smaller datasets!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# selct sample size and condition to be met (<100 +-) of fetures to compare to.\n",
    "# scatter(x='YOUR_COLUMN_x', y='YOUR_COLUMN_Y') is ONLY the labels you can name them anything!!\n",
    "df[df['YOUR_COLUMN_x'] < 100].sample(100).plot.scatter(x='YOUR_COLUMN_x_label', y='YOUR_COLUMN_Y_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hexplot\n",
    "> A hex plot aggregates points in space into hexagons, and then colors those hexagons based on the values within them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# selct sample size and condition to be met (<100 +-) of fetures to compare to.\n",
    "# scatter(x='YOUR_COLUMN_x', y='YOUR_COLUMN_Y') is ONLY the labels you can name them anything!!\n",
    "df[reviews['YOUR_COLUMN_x'] < 100].plot.hexbin(x='YOUR_COLUMN_x_label', y='YOUR_COLUMN_Y_label', gridsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Stacked plots\n",
    ">  A stacked chart is one which plots the variables one on top of the other. Many pandas multivariate plots expect input data to be in this format, with one categorical variable in the columns, one categorical variable in the rows, and counts of their intersections in the entries.\n",
    "\n",
    "- Is best to make a smaller sample dataframe frame for calualtions and visulizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plots entire dataframe\n",
    "df.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Area Plot\n",
    "> Same principles as \"Stacked Plot\" mixed with a line chart instead of a bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Like single-variable area charts, multivariate area charts are meant for nominal categorical or interval variables.\n",
    "\n",
    "Stacked plots are visually very pretty. However, they have two major limitations.\n",
    "\n",
    "The first limitation is that the second variable in a stacked plot must be a variable with a very limited number of possible values (probably an ordinal categorical, as here). Five different types of wine is a good number because it keeps the result interpretable; eight is sometimes mentioned as a suggested upper bound. Many dataset fields will not fit this critereon naturally, so you have to \"make do\", as here, by selecting a group of interest.\n",
    "\n",
    "The second limitation is one of interpretability. As easy as they are to make, and as pretty as they look, stacked plots make it really hard to distinguish concrete values. For example, looking at the plots above, can you tell which wine got a score of 87 more often: Red Blends (in purple), Pinot Noir (in red), or Chardonnay (in green)? It's actually really hard to tell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plots entire dataframe\n",
    "df.plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bivariate Line Chart\n",
    ">Bivariate Line Chat is highly effective Because the line in this chart takes up so little visual space, it's really easy and effective to overplot multiple lines on the same chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plots entire dataframe\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## SeaBorn Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import Seaborn agian for good measmeasure \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set parameters and themes\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = [6, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load DataFrame into SeaBorn\n",
    "\n",
    "> You must load datafram and colum vectors into seaborn valrible to proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Join Plots\n",
    "> URL: http://seaborn.pydata.org/generated/seaborn.jointplot.html?highlight=join%20plot\n",
    "\n",
    "- requires x, y vectors or keys in data values\n",
    "- More Seaborn plots and tutorials: http://seaborn.pydata.org/tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Purple JoinPlot (color='m')\n",
    "# USE SEABORN TO PLOT JOINGRID PLOT\n",
    "# Custom the inside plot: options are: “scatter” | “reg” | “resid” | “kde” | “hex”\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "sns.jointplot(x=obj_df[\"YOUR_COLUMN_X\"], y=obj_df[\"YOUR_COLUMN_Y\"], kind='reg', truncate=True, xlim=(0, 60), ylim=(0, 5), color=\"m\", height=10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Blue JoinPlot (edgecolor=\"skyblue\")\n",
    "# USE SEABORN TO PLOT JOINGRID PLOT\n",
    "# Custom the inside plot: options are: “scatter” | “reg” | “resid” | “kde” | “hex”\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "sns.jointplot(x=obj_df[\"YOUR_COLUMN_X\"], y=obj_df[\"YOUR_COLUMN_Y\"], kind='scatter', height=15,linewidth=2, edgecolor=\"skyblue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Advanced Statistics and Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Multiple regresion Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# multiple histograms\n",
    "\n",
    "df = df.set_index(['YOUR_COLUMN'])\n",
    "df.iloc[0]=0\n",
    "df=df.cumsum()\n",
    "    \n",
    "#Create Displot loop through column data features\n",
    "for column in df.columns:\n",
    "    plt.figure()             \n",
    "    sns.distplot(df[column])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
