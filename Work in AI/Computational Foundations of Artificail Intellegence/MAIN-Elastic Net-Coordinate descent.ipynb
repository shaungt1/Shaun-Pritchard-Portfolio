{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MAIN-Elastic Net-Coordinate descent.ipynb","private_outputs":true,"provenance":[{"file_id":"1WxYc1XnGrmsQuPZRl8I9ftGlHTXQCL3F","timestamp":1636138426754},{"file_id":"1U4auJBgbmX8zJM2SVhTXCrb-FljJM7v4","timestamp":1636135120587},{"file_id":"1kgwZKavM7smW_19x9H4OsE1cmdwVe9NN","timestamp":1636129348685},{"file_id":"1HDDGiRVIsOvJ_odQd3Ci2b6l408RB0rC","timestamp":1636125165497}],"collapsed_sections":[],"authorship_tag":"ABX9TyN9eVjXDfrtmK5qm1L43y4y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FOgaFwdekNsd"},"source":["## **Import data**"]},{"cell_type":"code","metadata":{"id":"7yBHZwnwjoZT"},"source":["#Math libs\n","from math import sqrt\n","from scipy import stats\n","import os\n","# Data Science libs\n","import numpy as np\n","import pandas as pd\n","# Graphics libs\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","#Timers\n","!pip install pytictoc\n","from pytictoc import TicToc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJp9HKx_udBj"},"source":["## **Import Data**"]},{"cell_type":"code","metadata":{"id":"pOi-sBx0j8qm"},"source":["# Import Data\n","df = pd.read_csv('/content/Credit_N400_p9.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXfExwHBj8xh"},"source":["# Validate data import\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C33uztDMkU_c"},"source":["## **Data Pre Proccessing**"]},{"cell_type":"code","metadata":{"id":"DatKXUT34Jkr"},"source":["# Assign dummy variables to catigorical feature attributes\n","df = df.replace({'Male': 0, 'Female':1, 'No': 0, 'Yes': 1})\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BevwL9qB4NtL"},"source":["# separate the predictors from the response\n","X = df.to_numpy()[:, :-1]\n","Y = df.to_numpy()[:, -1]\n","print('Convert dataframe to numpy array:', X.shape, Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_s1rQXpJjLLT"},"source":["## **Set Global Variables**"]},{"cell_type":"code","metadata":{"id":"hA_7cIsrosCE"},"source":["# Set local variables\n","# 9-Tuning Parms\n","λ  = [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]\n","\n","# 6 learning & convergence rate\n","α =  [0, 0.2, 0.4, 0.6, 0.8, 1]\n","\n","# K-folds\n","k = 5\n","\n","#Iterations\n","n_iters = 1000 # itterations\n","\n","#log base of lambda\n","λ_log = np.log10(λ) \n","\n","# Set verbose to True\n","verbose = True\n","\n","# Set n x m matrix variable\n","X_p = X\n","\n","# Set n vector variable\n","Y_p  = Y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iMnL5CwBjPhm"},"source":["## **Instantiate Data**"]},{"cell_type":"code","metadata":{"id":"ynQQ1wIN-SXl"},"source":["# Randomize N x M and N data\n","def randomize_data(X_p, Y_p):\n","  matrix = np.concatenate((X_p, Y_p[:, None]), 1)\n","  np.random.shuffle(matrix)\n","  return matrix[:, :-1], matrix[:, -1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KiNOOxosHO"},"source":["# Initilize random sample data\n","x, y = randomize_data(X_p, Y_p)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgu8IUMUeH-k"},"source":["# get number of samples and number of features\n","X1 = x.shape[0]\n","X2 = x.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_bpEMBlWCg0"},"source":["# create a 𝛽 matrix to store the predicted values \n","𝛽 = np.zeros([k, len(λ), len(α), X2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMQG63nQV1UQ"},"source":["# Store 5 K-fold cross validation results \n","CV = np.zeros([k, len(λ), len(α)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAgvJF3KV1bv"},"source":["# Compute the number of validation test samples and indices  based on k-folds \n","test_x = X1 // k \n","test_i = list(range(0, X1, test_x))\n","        \n","if True:\n","    print('Implemnting {} training by {} test validation samples for each 5-k CV fold.'.format(\n","        X1 - test_x, test_x)\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZkDFhL6kScT"},"source":["## **Implment Functions**"]},{"cell_type":"code","metadata":{"id":"QleECgSIosTw"},"source":["# Standardize  X\n","def standardize(x, mean_x, std_x):\n","  return (x - mean_x) / std_x "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJz8vo3IAV8u"},"source":["# Center response variables\n","def centerResponses(y, mean):\n","  return y - mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3xgYvv-AWCc"},"source":["# predicit x\n","def predict(x):\n","  x = standardize(x, mean_x, std_x)\n","  return np.matmul(x, 𝛽x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7juI0vRtuxg6"},"source":["### **Coordinate Descent Algortihm**"]},{"cell_type":"code","metadata":{"id":"QxvKcBJVAWHJ"},"source":["# implement Coordinate Descent\n","def CoordinateDescent(x, y, 𝛽x, sum_sq, lamb, alpha):\n","  for k in range(X2):\n","    # RSS minus the k coefficient \n","    RSS = y - np.matmul(x, 𝛽x) + (x[:, k] * 𝛽x[k])[:, None]\n","            \n","    # Calualte the RSS Loss function\n","    a_k = np.matmul(x[:, k].T, RSS)[0]\n","            \n","    # update B_k\n","    𝛽k = np.absolute(a_k) - lamb * (1 - alpha) / 2\n","    𝛽k = 𝛽k if 𝛽k >= 0 else 0\n","    𝛽x[k, 0] = np.sign(a_k) * 𝛽k / (sum_sq[k] + lamb * alpha)\n","\n","  return 𝛽x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcBl1vzBu7p9"},"source":["### **Elastic Net Cross Validation Algorithm**"]},{"cell_type":"code","metadata":{"id":"8dJP6KSdfc1z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXIkRce8fc-U"},"source":["def elasticNetCV(X, Y, λ , α, k, n_iters, verbose = True):\n","  for i_lambda, lamb in enumerate(λ): # loop through λ lambda\n","        for i_alpha, alpha in enumerate(α): # loop through α\n","            for i_fold, i_test in zip(range(k), test_i): # loop through folds\n","\n","                # Get the folds and split the data into training and validation sets     \n","\n","                x_test = x[i_test:i_test + test_x]\n","\n","                x_train = np.delete(x, np.arange(i_test, i_test + test_x), axis = 0)\n","\n","                y_test = y[i_test:i_test + test_x]\n","\n","                y_train = np.delete(y, np.arange(i_test, i_test + test_x), axis = 0)\n","\n","\n","                # Standardize x and center y folds\n","                mean_x, std_x = np.mean(x_train, 0), np.std(x_train, 0)\n","               \n","                mean_res = np.mean(y_train)\n","\n","\n","                x_train = standardize(x_train, mean_x, std_x)\n","\n","                x_test = standardize(x_test, mean_x, std_x)\n","\n","                y_train = centerResponses(y_train, mean_res)[:, None]\n","\n","                y_test = centerResponses(y_test, mean_res)[:, None]\n","                      \n","                # compute b_k given this fold \n","                sum_sq = np.sum((x_train))**2\n","                # print('Sum of Square test', sum_sq)\n","              \n","\n","                # initialize random 𝛽x for lambda and fold\n","                𝛽x = np.random.uniform(low = -1, high = 1, size = (X2, 1))\n","\n","\n","                # Iterate 1000 times through the beta values in Elastic Net algorithm\n","                for iter in range(n_iters):\n","                    𝛽x = CoordinateDescent(x_train, y_train, 𝛽x, sum_sq, lamb, alpha)\n","                \n","                # Score the models MSE\n","                y_hat = np.matmul(x, 𝛽x)\n","                mse_score = np.mean(y - y_hat)\n","              \n","                # store the score with the tuning param combinations\n","                CV[i_fold, i_lambda, i_alpha] = mse_score\n","\n","                # store the coefficient vector\n","                𝛽[i_fold, i_lambda, i_alpha] = 𝛽x[:, 0]\n","                \n","\n","                # if verbose flag, then print out the mean CV MSE for the combo of lambda and alpha\n","            if verbose:\n","               print('lambda:{}; alpha:{}; CV MSE:{}'.format(\n","                    lamb, alpha, np.mean(CV[:, i_lambda, i_alpha])))\n","                "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WH-j9kuqgGZc"},"source":["en = elasticNetCV(X, Y, λ , α, k, n_iters, verbose = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhEZ_jC9gGfv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YLzdlcirWAv"},"source":["for i_lambda, lamb in enumerate(λ): # loop through λ lambda\n","        for i_alpha, alpha in enumerate(α): # loop through α\n","            for i_fold, i_test in zip(range(k), test_i): # loop through folds\n","\n","                # Get the folds and split the data into training and validation sets     \n","\n","                x_test = x[i_test:i_test + test_x]\n","\n","                x_train = np.delete(x, np.arange(i_test, i_test + test_x), axis = 0)\n","\n","                y_test = y[i_test:i_test + test_x]\n","\n","                y_train = np.delete(y, np.arange(i_test, i_test + test_x), axis = 0)\n","\n","\n","                # Standardize x and center y folds\n","                mean_x, std_x = np.mean(x_train, 0), np.std(x_train, 0)\n","               \n","                mean_res = np.mean(y_train)\n","\n","\n","                x_train = standardize(x_train, mean_x, std_x)\n","\n","                x_test = standardize(x_test, mean_x, std_x)\n","\n","                y_train = centerResponses(y_train, mean_res)[:, None]\n","\n","                y_test = centerResponses(y_test, mean_res)[:, None]\n","                      \n","                # compute b_k given this fold \n","                sum_sq = np.sum((x_train))**2\n","                # print('Sum of Square test', sum_sq)\n","              \n","\n","                # initialize random 𝛽x for lambda and fold\n","                𝛽x = np.random.uniform(low = -1, high = 1, size = (X2, 1))\n","\n","\n","                # Iterate 1000 times through the beta values in Elastic Net algorithm\n","                for iter in range(n_iters):\n","                    𝛽x = CoordinateDescent(x_train, y_train, 𝛽x, sum_sq, lamb, alpha)\n","            \n","            \n","                # Score the models MSE\n","                y_hat = np.matmul(x, 𝛽x)\n","                mse_score = np.mean(y - y_hat)\n","              \n","                # store the score with the tuning param combinations\n","                CV[i_fold, i_lambda, i_alpha] = mse_score\n","\n","                # store the coefficient vector\n","                𝛽[i_fold, i_lambda, i_alpha] = 𝛽x[:, 0]\n","                \n","\n","                # if verbose flag, then print out the mean CV MSE for the combo of lambda and alpha\n","            if True:\n","               print('lambda:{}; alpha:{}; CV MSE:{}'.format(\n","                    lamb, alpha, np.mean(CV[:, i_lambda, i_alpha])))\n","                \n","          \n","############# Retrain on entire dataset with optimal lambda and alpha #############\n","# find the best lambda and alpha\n","        \n","cv_mean = np.mean(CV, 0)\n","best_λ_ind, best_alpha_ind = np.where(cv_mean == np.amin(cv_mean))\n","\n","best_λ = λ[best_λ_ind[0]]\n","best_alpha = α[best_alpha_ind[0]]\n","\n","\n","# standardize features of x and center responses \n","mean_x, std_x = np.mean(x, 0), np.std(x, 0)\n","x = standardize(x, mean_x, std_x)\n","y = centerResponses(y, np.mean(y))[:, None]\n","                                    \n","\n","# compute the sum of squares for each feature on the entire dataset\n","sum_sq = np.sum(x ** 2, 0)\n","                                    \n","# initialize coefficients\n","𝛽x = np.random.uniform(low = -1, high = 1, size = (X2, 1))\n","\n","# perform updates \n","for iter in range(n_iters):\n","    𝛽x = CoordinateDescent(x, y, 𝛽x, sum_sq, best_λ, best_alpha)\n","    # print('Beta values updated test:', B) \n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pg4AB7akza8k"},"source":["## **Devliverable 1**"]},{"cell_type":"code","metadata":{"id":"ndSBpD-1CrvA"},"source":["# observe the coefficient values as a function of lambda for each alpha\n","# plotting mean coefficient vectors over the 5 folds\n","\n","sns.set_theme()\n","sns.set_style(\"darkgrid\", {\"grid.color\": \".5\", \"grid.linestyle\": \":\" })\n","𝛽μ  = np.mean(𝛽,0)\n","ŷ = df.columns\n","count = 0\n","t = TicToc()  # create instance of class\n","\n","for i_alpha, alpha in enumerate(α):\n","    count += 1 \n","    end_time = t.toc()\n","    plt.figure()\n","    plt.figure(figsize=(16, 10), dpi=70)\n","    print('Tuning parameter converged at = #{c} λ {} at alpha{α}\\n'.format(np.log10(λ), c=count,  α=alpha)) \n","    for i_beta in range(𝛽μ.shape[1]):\n","        plt.plot( np.log10(λ), 𝛽μ[:, i_alpha, i_beta], label = ŷ[i_beta])\n","    plt.legend(bbox_to_anchor = (1.05, 1), loc = 'upper right', title = 'Features')\n","    plt.xlabel('λ Tuning Params')\n","    plt.ylabel('Coefficient Values')\n","    plt.title('Alpha Value: {}'.format(alpha))\n","    plt.show()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kDgnB6A84USt"},"source":["print(CV)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUNc9q724UVc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"82q1LiHa4UYt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xEn-WB4-Jsw"},"source":["### **Output for Deliverable 2**"]},{"cell_type":"code","metadata":{"id":"H8Ju28nKt6yD"},"source":["# observe the CV MSE over values of lambda and alpha\n","plt.figure()\n","plt.figure(figsize=(16, 10), dpi=70)\n","for i_alpha, alpha in enumerate(α):\n","    std_error = np.std(CV[..., i_alpha], 0) / np.sqrt(k)\n","    plt.errorbar( np.log10(λ), np.mean(CV[..., i_alpha], 0), yerr = std_error,xuplims=True,label = str(alpha))\n","    plt.xlabel('Log base lambda')\n","    plt.ylabel('Cross Validation MSE')\n","    plt.legend(title = 'α')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W0-7CMo--LvE"},"source":["### **Output for Deliverable 3**"]},{"cell_type":"code","metadata":{"id":"qC5Hs87Mt61h"},"source":["# lambda and alpha with lowest cv mse\n","print('Best lambda: {}; Best alpha: {}'.format(best_λ, best_alpha))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TpFGTQox-NsW"},"source":["### **Output for Deliverable 4**"]},{"cell_type":"code","metadata":{"id":"kxqhfVdAt65Q"},"source":["# coefficient vector for optimal lambda given alpha = 0 (lasso)\n","# coefficicents look relatively similar to elastic net\n","\n","# get cv mse given alpha = 0\n","cv_mse_alpha_0 = np.mean(CV[..., 0], 0)\n","\n","# find index of lambda with lowest cv mse\n","lambda_ind = np.argmin(cv_mse_alpha_0)\n","lambda_optimal = λ[lambda_ind]\n","\n","# get the mean coefficient vector under lambda and alpha for all 5 folds\n","B_mean = np.mean(𝛽x[:, lambda_ind, 0, :], 0)\n","\n","# plot against B with optimal lambda and alpha\n","plt.scatter(B, B_mean)\n","plt.plot(np.arange(-300, 475), np.arange(-300, 475), '--', color = 'r')\n","plt.xlabel('Elastic Net (lambda = {}, alpha = {})'.format(best_λ, best_alpha))\n","plt.ylabel('Lasso (lambda = {})'.format(lambda_optimal))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqgO6TtR-Pvg"},"source":["### **Output for Deliverable 6**"]},{"cell_type":"code","metadata":{"id":"orTqQy_Pt672"},"source":["# coefficient vector for optimal lambda given alpha = 1 (ridge)\n","# coefficients look similar to elastic net and lasso\n","# because best alpha was in the middle\n","\n","# get cv mse given alpha = 1\n","cv_mse_alpha_1 = np.mean(CV[..., -1], 0)\n","\n","# find index of lambda with lowest cv mse\n","lambda_ind = np.argmin(cv_mse_alpha_1)\n","lambda_optimal = λ[lambda_ind]\n","\n","# get the mean coefficient vector under lambda and alpha for all 5 folds\n","B_mean = np.mean(𝛽x[:, lambda_ind, -1, :], 0)\n","\n","# plot against B with optimal lambda and alpha\n","plt.scatter(B, B_mean)\n","plt.plot(np.arange(-300, 475), np.arange(-300, 475), '--', color = 'r')\n","plt.xlabel('Elastic Net (lambda = {}, alpha = {})'.format(best_λ, best_alpha))\n","plt.ylabel('Ridge (lambda = {})'.format(lambda_optimal))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbDOHs0_t6-t"},"source":["# predict responses and compare against actual responses\n","y_hat = predict(x)\n","plt.scatter(y_hat, y)\n","plt.xlabel('Predicted Response')\n","plt.ylabel('Actual Response')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_M0-V6o7uiCn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MM6sUx-IuiSx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4zL0upzuidX"},"source":[""],"execution_count":null,"outputs":[]}]}