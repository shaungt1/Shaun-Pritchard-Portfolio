{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPritchard_CAP5625_Programming_Assignment 1_Libaries_10182021.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNcAsfXa9_P5"
      },
      "source": [
        "- **Programmer: Shaun Pritchard**\n",
        "- **Date: 10-10-2021**\n",
        "- **Assignment: 1**\n",
        "- **Prof: Michael DeGiorgio**\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ1gli08SYjs"
      },
      "source": [
        "# **CAP 52625 COMPUTATIONAL FOUDNATIONS OF AI**\n",
        "\n",
        "##Ridge Regression using Gradient Descent using Scikit Learn - Assignment 1\n",
        "<hr>\n",
        "\n",
        "**Perform a penalized (regularized) least squares fit of a linear model using ridge regression, with the model parameters obtained by batch gradient descent. The tuning parameter will be chosen using five-fold cross validation, and the best-fit model parameters will be inferred on the training dataset conditional on an optimal tuning parameter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRX_tcbwc_N"
      },
      "source": [
        "## **Deliverables**\n",
        "*   **Deliverable 6**  Implement the assignment using statistical or machine learning libraries in a language of your choice.Compare the results with those obtained above, and\n",
        "provide a discussion as to why you believe your results are different if you found them to be different.\n",
        "\n",
        "> Note:  I implemented 2 variations of the cross validation tuning prama error output charts using using the absolute vlaue on the regression errors to check variation as per the asignment.\n",
        "\n",
        "\n",
        "\n",
        "***Deliverable 1-5 located here:***\n",
        "https://colab.research.google.com/gist/shaungt1/83c9e75f7062e34897957859165f3a0d/spritchard_cap5625_programming_assignment-1_10182021.ipynb\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbAYHRUvbq4E"
      },
      "source": [
        "## **Set Up and Import Data for proccessing**\n",
        "> Import the credit balance dataset \n",
        "- ùëÅ=400 training  observations\n",
        "- ùëù=9 features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrhW9xpBSYLI"
      },
      "source": [
        "#Project Imports\n",
        "# Data Science libs\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Graphics libs\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# labries for stat testing\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "# sklearn liabries for ridge regression and cross vlaidation\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRE1hbjm3LR0"
      },
      "source": [
        "# Mount Google Drive for data access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOIEgTDMrINB"
      },
      "source": [
        "# Set up dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/Florida_Atlantic_University/Computational_Foundations_of_ AI/Credit_N400_p9.csv')\n",
        "# Set up datafeme for testing\n",
        "# df = pd.read_csv('/content/Credit_N400_p9.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZumbzNoi30jq"
      },
      "source": [
        "# Check the imported data & features\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLrk5odUoNXS"
      },
      "source": [
        "## **Pre-Proccess Data**\n",
        "\n",
        "- Re-assign categorical featre attributes with bianary dummy variables\n",
        "- Split real X and y nx1 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePVYk-CPq0SG"
      },
      "source": [
        "#Assign dummy variables to catigorical features with new dataframe\n",
        "df1 = df.replace({'Male': 0, 'Female':1, 'No': 0, 'Yes': 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WhJpw8f8yFL"
      },
      "source": [
        "# Validate categorical dummy variables\n",
        "df1.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecSkQET33cTn"
      },
      "source": [
        "# Seperate real features to variable X\n",
        "X = df1.iloc[:, :-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Ny-XzSp3vG"
      },
      "source": [
        "# Seperate real features to variable X\n",
        "y = df1.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSlSuW6e5wQH"
      },
      "source": [
        "# Check X features\n",
        "print('Matrix shape X := {X}\\nValidate array:(row:col)'  .format(X = X.shape), '\\n', X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcu5ZBCV52JG"
      },
      "source": [
        "# Check y features\n",
        "print('Matrix shape y := {y}\\nValidate array:(row:col)'  .format(y = y.shape), '\\n', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlbrBOwOy_pf"
      },
      "source": [
        "## **Scale, Center and Standardize Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S8XvkYK59Cf"
      },
      "source": [
        "# Implement standardize used for X with SciKit learn\n",
        "standardize = StandardScaler()\n",
        "#Implement Center for y (implemented in scikit learn Ridge() method)\n",
        "y_center = StandardScaler(with_std=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdyya49M9xu9"
      },
      "source": [
        "# Apply standardize to X\n",
        "X = standardize.fit_transform(X)\n",
        "X = pd.DataFrame(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-vF4VTi93gW"
      },
      "source": [
        "# Label column headers for X\n",
        "X.columns=['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Gender', 'Student', 'Married']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOOmUxLK93jU"
      },
      "source": [
        "# Check X column head\n",
        "print('X standardized feture vector\\n', X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8dDm40YzPJc"
      },
      "source": [
        "## **Evaluate Model with Ridge Regression BGD w/ Scikit Learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5cKdL0CqL3i"
      },
      "source": [
        "# Set local tunning parameters \n",
        "Œª=[1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1omWHJ593tW"
      },
      "source": [
        "# Evaluate tuning parameters with ridge regression L2 penalty\n",
        "ùõΩx=[] # set empty list\n",
        "for lamb in Œª:\n",
        "    # Solver set to auto to best fit data \n",
        "    ridge=Ridge(alpha=lamb, max_iter=1000)\n",
        "    # fir the ridge regression coefficients\n",
        "    ridge.fit(X, y)\n",
        "    print('X & y features:={}\\n'.format(ridge.fit(X, y)))\n",
        "    ùõΩx.append(ridge.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPvW-jdsAJy8"
      },
      "source": [
        "## **Deliverable 1**\n",
        "- Build graph of dataset N=9 features tuning parameter effect on inferred Ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNvmM8Hi93wx"
      },
      "source": [
        "# Output Deviverable 6.1: inferred tuning parmeters of ridge regresion using libaries\n",
        "sns.set_theme()\n",
        "sns.set_style(\"darkgrid\", {\"grid.color\": \".5\",\"image.cmap\": \"mako\", \"grid.linestyle\": \":\" })\n",
        "dev1=pd.DataFrame(ùõΩx)\n",
        "dev1.index=Œª\n",
        "dev1.columns=['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Gender', 'Student', 'Married']\n",
        "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
        "dev1.plot()\n",
        "plt.title('Deliverable 6.1: Tuning parameter effect on inferred Ridge Regression')\n",
        "plt.xlabel('Œª Tuning Params')\n",
        "plt.ylabel('p=9 features')\n",
        "plt.xscale('log')\n",
        "plt.legend(loc='lower right', title='Beta_Œª')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q_0vc7R8Xoz"
      },
      "source": [
        "## **(5) K-fold Cross Validation Algorithm w/ Scikit Learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV1T7HY9Aulg"
      },
      "source": [
        "# Evaluate Ridge with CV gridsearch 5 k-folds 1000 iterations\n",
        "ridge=Ridge(max_iter=1000)\n",
        "parameters={'alpha': Œª}\n",
        "# Calculate MSE \n",
        "MSE=make_scorer(mean_squared_error, greater_is_better=False)\n",
        "# use grid search with 5-k-folds\n",
        "ridge_regressor=GridSearchCV(ridge, parameters, scoring=MSE, cv=5, refit=False)\n",
        "# Fit ridge regression to cross validation folds\n",
        "ridge_regressor.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPF9EbfzAv-z"
      },
      "source": [
        "## **Deliverable 2**\n",
        "\n",
        " Illustrate the effect of the tuning parameter on the cross-validation error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bqZdJHUAuo-"
      },
      "source": [
        "# Plot the effect of the tuning parameter on the cross-validation error\n",
        "sns.set_theme()\n",
        "sns.set_style(\"darkgrid\", {\"grid.color\": \".5\",\"image.cmap\": \"mako\", \"grid.linestyle\": \":\" })\n",
        "plt.plot(Œª, np.absolute(ridge_regressor.cv_results_['mean_test_score']), color=\"purple\")\n",
        "plt.title('Effect of the tuning parameter on the 5 K-fold CV error')\n",
        "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Œª')\n",
        "plt.ylabel('CV error')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 16), dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LiSKzVa2LHK"
      },
      "source": [
        "## **Deliverable 3** \n",
        "Indicate the value of ùúÜ that generated the smallest CV(5)error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBXQlOiAus6"
      },
      "source": [
        "# Output final results of lowest Œª tuning param and best score\n",
        "print(\"Best MSE score of Œª\\n\", ridge_regressor.best_score_)\n",
        "print(\"Best params of Œª\\n\",ridge_regressor.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XMKjOL2jdG"
      },
      "source": [
        "## **Deliverable 4** \n",
        "\n",
        "- Given the optimal ùúÜ, retrain your model on the entire dataset of ùëÅ = 400 observations and provide the estimates of the ùëù = 9 best-fit model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGwuhgqkAuvd"
      },
      "source": [
        "# Retrain model based on Œª = 1.0\n",
        "ridge=Ridge(alpha=1, max_iter=1000)\n",
        "# Fit data\n",
        "ridge.fit(X, y)\n",
        "# Output coefficients based on retrianed model at  Œª = 1.0\n",
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTa74uQDHjdK"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## **Alternate 2nd CV error Algorthm |X|**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4IVyWIXFu4u"
      },
      "source": [
        "#Evaluate Ridge with CV gridsearch 5 k-folds 1000 iterations\n",
        "# using grid search hyperparameters for ridge regression\n",
        "# define model find best tuning param errors\n",
        "model = Ridge()\n",
        "# define model evaluation method\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "# define grid\n",
        "grid = dict()\n",
        "grid['alpha'] = Œª # set parementer to 1e-5\n",
        "# define search\n",
        "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# perform the search\n",
        "results = search.fit(X, y)\n",
        "# summarize\n",
        "print('ùúÜ that generated the smallest CV(5)error')\n",
        "print('MSE: %.3f' % results.best_score_)\n",
        "print('Config: %s' % results.best_params_)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnV-9UTWIeCp"
      },
      "source": [
        "# Illustrate the effect of the tuning parameter on the cross-validation error\n",
        "plt.plot(Œª, np.absolute(ridge_regressor.cv_results_['mean_test_score']), color=\"green\")\n",
        "plt.title('Effect of the tuning parameter on the 5 K-fold CV error')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Œª')\n",
        "plt.ylabel('CV error')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 16), dpi=90)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}